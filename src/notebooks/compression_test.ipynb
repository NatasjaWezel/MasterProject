{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for automatic reloading of imports and makes it unncessecary to restart the kernel\n",
    "# whenever a function is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# show matplotlib plots in-line\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import sys\n",
    "\n",
    "# so we can import scripts from the scripts folder, although it is not a child repository\n",
    "sys.path.append('..//scripts//')\n",
    "\n",
    "from helpers.density_helpers import count_points_per_square, prepare_df\n",
    "from constants.paths import WORKDIR\n",
    "from classes.Settings import Settings\n",
    "from classes.Radii import Radii\n",
    "\n",
    "from calc_avg_fragment import calc_avg_frag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df(amount, df):\n",
    "    \"\"\" deze functie pakt aantal/percentage random uit lijst \"\"\"\n",
    "    \n",
    "    df = df.sample(n=amount)\n",
    "    \n",
    "    \n",
    "    assert len(df) == amount, \"Sampling went wrong\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = pd.read_csv('../../results/volumes_free.csv')\n",
    "\n",
    "def compression(central, contact, to_count, amounts, runs):               \n",
    "    resolution = 0.20\n",
    "    cluster_frac = 0.10\n",
    "\n",
    "    datafile = \"..\\\\data\\\\\" + central + \"\\\\\" + central + \"_\" + contact + \"_vdw.5.cor\"\n",
    "    \n",
    "    \n",
    "    settings = Settings(WORKDIR, datafile)\n",
    "    settings.set_atom_to_count(to_count)\n",
    "    settings.set_resolution(round(resolution, 2))\n",
    "\n",
    "    df = pd.read_csv(settings.get_structure_csv_filename())\n",
    "\n",
    "    print(f\"Structures {len(df)}\")\n",
    "    coordinate_df = pd.read_hdf(settings.get_coordinate_df_filename(), settings.get_coordinate_df_key())\n",
    "    \n",
    "    display(coordinate_df)\n",
    "    \n",
    "    display(df)\n",
    "    df = df[df.index.isin(list(coordinate_df.fragment_id))]\n",
    "\n",
    "    print(f\"Coordinate df {len(coordinate_df)}\")\n",
    "    aligned_fragments_df = pd.read_csv(settings.get_aligned_csv_filename())\n",
    "\n",
    "    for run in range(runs):\n",
    "        for amount in amounts:       \n",
    "            print(f\"Amount: {amount}, Run: {run}\")\n",
    "            \n",
    "            # grab random structures\n",
    "            sampled_df = sample_df(amount, df)\n",
    "            structure_indices = sampled_df.index.to_list()\n",
    "\n",
    "            # select rows from dfs\n",
    "            coordinate_sampled = coordinate_df[coordinate_df.fragment_id.isin(structure_indices)]\n",
    "            \n",
    "            assert len(coordinate_sampled) == amount, \"Sampling went wrong\" + str(len(coordinate_sampled)) + \" \" + str(amount)\n",
    "            aligned_sampled = aligned_fragments_df[(aligned_fragments_df.fragment_id.isin(structure_indices)) & (aligned_fragments_df.label != \"-\")]\n",
    "\n",
    "            # make radii object to get vdw radii\n",
    "            radii = Radii(settings.get_radii_csv_name())\n",
    "\n",
    "            # calc new avg fragment\n",
    "            fragment = calc_avg_frag(aligned_sampled, settings, radii)\n",
    "            \n",
    "            empty_density_df = prepare_df(df=coordinate_sampled, settings=settings)\n",
    "            print(f\"Amount in empty density df {empty_density_df[to_count].sum()}\")\n",
    "            density_df = count_points_per_square(df=empty_density_df, contact_points_df=coordinate_sampled, settings=settings)\n",
    "            \n",
    "            density_df['datafrac_normalized'] = density_df[to_count] / density_df[to_count].sum()\n",
    "            \n",
    "            print(f\"Normalized datafrac: {density_df['datafrac_normalized'].sum()}\")\n",
    "            print(f\"Amount in density df {density_df[to_count].sum()}\")\n",
    "\n",
    "            threshold = density_df.datafrac_normalized.max() * cluster_frac\n",
    "\n",
    "            in_cluster = density_df[density_df.datafrac_normalized >= threshold]\n",
    "            Vavailable = volumes.loc[(volumes.central == central) & (volumes.contact == contact) & (volumes.to_count == to_count), 'volume'].item()  \n",
    "\n",
    "            datafrac = in_cluster.datafrac_normalized.sum()\n",
    "            Vcluster = len(in_cluster) * resolution**3\n",
    "\n",
    "            directionality = datafrac / Vcluster * (Vavailable/2)        \n",
    "\n",
    "            with open('results_corrected.csv', 'a', newline=\"\") as resultsfile:\n",
    "                writer = csv.writer(resultsfile)\n",
    "                writer.writerow([central, contact, to_count, resolution, cluster_frac, run, amount, datafrac, Vcluster, Vavailable, directionality])\n",
    "\n",
    "            print(central, contact, to_count, resolution, cluster_frac, run, amount, directionality)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('results.csv', header=0)\n",
    "# df_corrected = df.copy()\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     central, contact, to_count, Vcluster, datafrac = row[\"central\"], row[\"contact\"], row[\"to_count\"], row[\"Vcluster\"], row[\"datafrac\"]\n",
    "#     Vavailable = volumes.loc[(volumes.central == central) & (volumes.contact == contact) & (volumes.to_count == to_count), 'volume'].item()  \n",
    "    \n",
    "#     directionality = datafrac / Vcluster * (Vavailable/2)   \n",
    "    \n",
    "#     df_corrected.at[i, \"Vavailable\"] = Vavailable\n",
    "#     df_corrected.at[i, \"directionality\"] = directionality\n",
    "    \n",
    "# display(df_corrected)\n",
    "\n",
    "# df_corrected.to_csv('results_corrected.csv', index=False)\n",
    "    \n",
    "    # with open('results.csv', 'w', newline=\"\") as resultsfile:\n",
    "#     writer = csv.writer(resultsfile)\n",
    "#     writer.writerow(['central', 'contact', 'to_count', 'resolution', 'cluster_frac', 'run', 'amount', 'datafrac', 'Vcluster', 'Vavailable', 'directionality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_again = False\n",
    "\n",
    "central1 = \"H2O\" # 559303 structures\n",
    "contact1= \"XH\"\n",
    "# to_count1 = \"H\"\n",
    "to_count1 = \"O\" # 460377\n",
    "\n",
    "central2 = \"RC6H5\" # 445710 structures\n",
    "contact2 = \"CCH3\"\n",
    "to_count2 = \"H\"\n",
    "\n",
    "amounts1 = [50, 100, 250, 500, 750,\n",
    "            1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, \n",
    "            15000, 20000, 30000, 40000, 50000, \n",
    "            100000, 150000, 200000, 250000, 300000, 350000, 400000]\n",
    "\n",
    "if run_again:\n",
    "    # compression(central1, contact1, to_count1, [460377] , 1)\n",
    "    compression(central2, contact2, to_count2, [445710], 1)\n",
    "    compression(central1, contact1, to_count1, [460377] , 1)\n",
    "#     compression(central2, contact2, to_count2, amounts1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Check CI intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_h2o_xh_o_05 = 5.058302741738474\n",
    "tru_rc6h5_cch3_h_05 = 1.6245673292050886\n",
    "\n",
    "tru_h2o_xh_o_02 = 11.032713274285268\n",
    "tru_rc6h5_cch3_h_02 = 2.174874888230874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_corrected.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc6h5_05 = df[(df.central == \"RC6H5\") & (df.resolution == 0.5)].copy()\n",
    "rc6h5_02 = df[(df.central == \"RC6H5\") & (df.resolution == 0.2)].copy()\n",
    "h2o_05 = df[(df.central == \"H2O\") & (df.resolution == 0.5)].copy()\n",
    "h2o_02 = df[(df.central == \"H2O\") & (df.resolution == 0.2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_rc6h5_05 = rc6h5_05.groupby(\"amount\")[\"directionality\"].agg([\"count\", \"std\", \"mean\"]).reset_index()\n",
    "stats_h2o_05 = h2o_05.groupby(\"amount\")[\"directionality\"].agg([\"count\", \"std\", \"mean\"]).reset_index()\n",
    "\n",
    "stats_rc6h5_02 = rc6h5_02.groupby(\"amount\")[\"directionality\"].agg([\"count\", \"std\", \"mean\"]).reset_index()\n",
    "stats_h2o_02 = h2o_02.groupby(\"amount\")[\"directionality\"].agg([\"count\", \"std\", \"mean\"]).reset_index()\n",
    "\n",
    "stats_h2o_05.columns = [\"amount\", \"count\", \"std\", \"average\"]\n",
    "stats_rc6h5_05.columns = [\"amount\", \"count\", \"std\", \"average\"]\n",
    "\n",
    "stats_h2o_02.columns = [\"amount\", \"count\", \"std\", \"average\"]\n",
    "stats_rc6h5_02.columns = [\"amount\", \"count\", \"std\", \"average\"]\n",
    "\n",
    "stats_rc6h5_05[\"percental\"] = abs((stats_rc6h5_05.average - tru_rc6h5_cch3_h_05)) / tru_rc6h5_cch3_h_05 * 100\n",
    "stats_rc6h5_02[\"percental\"] = abs((stats_rc6h5_02.average - tru_rc6h5_cch3_h_02)) / tru_rc6h5_cch3_h_02 * 100\n",
    "stats_h2o_05[\"percental\"] = abs((stats_h2o_05.average - tru_h2o_xh_o_05)) / tru_h2o_xh_o_05 * 100\n",
    "stats_h2o_02[\"percental\"] = abs((stats_h2o_02.average - tru_h2o_xh_o_02)) / tru_h2o_xh_o_02 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "fig.subplots_adjust(bottom=0.17)\n",
    "\n",
    "plt.title(\"Compression algorithm\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Amount of random datapoints\")\n",
    "plt.ylabel(\"Directionality - percental difference\")\n",
    "\n",
    "ax.scatter(stats_rc6h5_05.amount, stats_rc6h5_05.percental, color='rebeccapurple', label=\"RC6H5-CCH3(H), res: 0.5\")\n",
    "ax.plot(stats_rc6h5_05.amount, stats_rc6h5_05.percental, color='rebeccapurple')\n",
    "\n",
    "ax.scatter(stats_h2o_05.amount, stats_h2o_05.percental, color='blue', label=\"H2O-OH(O), res: 0.5\")\n",
    "ax.plot(stats_h2o_05.amount, stats_h2o_05.percental, color='blue')\n",
    "\n",
    "ax.scatter(stats_rc6h5_02.amount, stats_rc6h5_02.percental, color='green', label=\"RC6H5-CCH3(H), res: 0.2\")\n",
    "ax.plot(stats_rc6h5_02.amount, stats_rc6h5_02.percental, color='green')\n",
    "\n",
    "ax.scatter(stats_h2o_02.amount, stats_h2o_02.percental, color='red', label=\"H2O-OH(O), res: 0.2\")\n",
    "ax.plot(stats_h2o_02.amount, stats_h2o_02.percental, color='red')\n",
    " \n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('../../results/CI_compression_H2O_XH_H.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "fig.subplots_adjust(bottom=0.17)\n",
    "\n",
    "plt.title(\"Compression algorithm\")\n",
    "\n",
    "plt.xlabel(\"Amount of random datapoints\")\n",
    "plt.ylabel(\"Directionality - percental difference\")\n",
    "\n",
    "ax.scatter(stats_rc6h5_05.amount, stats_rc6h5_05.percental, color='rebeccapurple', label=\"RC6H5-CCH3(H), res: 0.5\")\n",
    "ax.plot(stats_rc6h5_05.amount, stats_rc6h5_05.percental, color='rebeccapurple')\n",
    "\n",
    "ax.scatter(stats_h2o_05.amount, stats_h2o_05.percental, color='blue', label=\"H2O-OH(O), res: 0.5\")\n",
    "ax.plot(stats_h2o_05.amount, stats_h2o_05.percental, color='blue')\n",
    "\n",
    "ax.scatter(stats_rc6h5_02.amount, stats_rc6h5_02.percental, color='green', label=\"RC6H5-CCH3(H), res: 0.2\")\n",
    "ax.plot(stats_rc6h5_02.amount, stats_rc6h5_02.percental, color='green')\n",
    "\n",
    "ax.scatter(stats_h2o_02.amount, stats_h2o_02.percental, color='red', label=\"H2O-OH(O), res: 0.2\")\n",
    "ax.plot(stats_h2o_02.amount, stats_h2o_02.percental, color='red')\n",
    " \n",
    "major_ticks_x = np.arange(0, 500000, 10000)\n",
    "minor_ticks_x = np.arange(0, 500000, 5000)\n",
    "\n",
    "major_ticks_y = np.arange(0, 101, 10)\n",
    "minor_ticks_y = np.arange(0, 101, 5)\n",
    "\n",
    "ax.set_xticks(major_ticks_x)\n",
    "ax.set_xticks(minor_ticks_x, minor=True)\n",
    "ax.set_yticks(major_ticks_y)\n",
    "ax.set_yticks(minor_ticks_y, minor=True)\n",
    "\n",
    "# Or if you want different settings for the grids:\n",
    "ax.grid(which='minor', alpha=0.2)\n",
    "ax.grid(which='major', alpha=0.5)\n",
    "\n",
    "ax.set_ylim(-2, 40)\n",
    "ax.set_xlim(0, 100000)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.vlines(5000, 0, 50, color=\"black\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('../../results/compression.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
