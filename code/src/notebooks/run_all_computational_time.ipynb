{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time al steps\n",
    "In this notebook, you can run all calculations and time how long the steps take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..//scripts//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# allows for automatic reloading of imports and makes it unncessecary to restart the kernel\n",
    "# whenever a function is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from constants.paths import WORKDIR, CENTRAL_GROUPS_CSV, RADII_CSV, METHYL_CSV\n",
    "\n",
    "from classes.Settings import Settings, AlignmentSettings\n",
    "from classes.Radii import Radii\n",
    "\n",
    "from helpers.alignment_helpers import (calc_rmse, kabsch_align, perform_rotations,\n",
    "                                       perform_translation, read_raw_data)\n",
    "from align_kabsch import align_all_fragments, split_file_if_too_big\n",
    "from calc_avg_fragment import calc_kabsch_rmse, calc_avg_rmse, reset_labels_with_kmeans\n",
    "from helpers.geometry_helpers import make_coordinate_df, average_fragment, add_model_methyl\n",
    "from helpers.density_helpers import prepare_df, make_density_df\n",
    "\n",
    "central_groups = [\"REt\", \"ArCI\", \"RCOMe\", \"RNO2\", \"ArCI\", \"REt\", \"NO3\", \"RC6F5\", \"H2O\", \"RC6H5\"] #\n",
    "contact_groups = [\"CF\", \"RCN\", \"R2CO\", \"XH\", \"XH\", \"CCH3\", \"C2CH2\", \"RC6H5\", \"ArCH\"]\n",
    "to_count =       [\"F\",   \"N\",    \"O\",   \"H\", \"O\",  \"H\",     \"H\", \"centroid\", \"H\"] \n",
    "\n",
    "resolutions = np.arange(0.1, 1.55, 0.05)\n",
    "resolutions = np.flip(resolutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = False\n",
    "counts = []\n",
    "\n",
    "if count:\n",
    "    with open('../../results/amounts_structures.csv', 'a', newline='') as resultsfile:\n",
    "        writer = csv.writer(resultsfile)\n",
    "        writer.writerow(['central', 'contact', 'amount_cif', 'amount_structures'])\n",
    "        \n",
    "        for central_group in central_groups:\n",
    "\n",
    "            for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "                datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "\n",
    "                ids = []\n",
    "\n",
    "                with open(datafile, 'r') as resultsFile:\n",
    "                    line = \"hoi\"\n",
    "                    while line:\n",
    "                        line = resultsFile.readline()\n",
    "                        if \"**\" in line:\n",
    "                            ids.append(line.split(\"**\")[0])\n",
    "\n",
    "                    print(central_group, contact_group, len(ids), len(set(ids)))\n",
    "                    counts.append(len(ids))\n",
    "\n",
    "                    writer.writerow([central_group, contact_group, len(ids), len(set(ids))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align, AVG fragment, Coordinate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_everything_again = True\n",
    "write_times = False\n",
    "\n",
    "if run_everything_again:\n",
    "    if write_times:\n",
    "        with open('results/redo_coordinate_df.csv', 'a', newline='') as resultsfile:\n",
    "            writer = csv.writer(resultsfile)\n",
    "            writer.writerow(['central', 'contact', 'to_count', 'coordinate_df'])\n",
    "\n",
    "    for central_group in central_groups:\n",
    "        for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "\n",
    "            print(central_group, contact_group, to_count_contact)\n",
    "\n",
    "            datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "            result1 = \"..\\\\..\\\\results\\\\pairs\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5\\\\\"\\\n",
    "                      + central_group + \"_\" + contact_group + \"_aligned.csv\" \n",
    "\n",
    "            if not os.path.exists(f\"..\\\\..\\\\results\\\\pairs\\\\{central_group}\"):\n",
    "                os.mkdir(f\"..\\\\..\\\\results\\\\pairs\\\\{central_group}\\\\\")\n",
    "\n",
    "            t0_alignment = time.time()\n",
    "\n",
    "            labelfile = datafile.rsplit('.', 1)[0] + '.csv'\n",
    "\n",
    "            settings = AlignmentSettings(\"..\\\\..\", datafile, labelfile)\n",
    "            settings.set_atom_to_count(to_count_contact)\n",
    "            settings.set_central_group_csv(CENTRAL_GROUPS_CSV)\n",
    "            settings.prepare_alignment()\n",
    "\n",
    "            split_file_if_too_big(settings.coordinate_file, settings.no_atoms)\n",
    "            settings.update_coordinate_filename()\n",
    "\n",
    "            # TODO: align only if not aligned yet\n",
    "            align_all_fragments(settings)\n",
    "\n",
    "            t1_alignment = time.time()\n",
    "            alignment_time = t1_alignment - t0_alignment\n",
    "\n",
    "            t0_avg_frag = time.time()\n",
    "\n",
    "            aligned_fragments_df = pd.read_csv(settings.get_aligned_csv_filename())\n",
    "\n",
    "            radii = Radii(RADII_CSV)\n",
    "            avg_frag = average_fragment(aligned_fragments_df, settings, radii)\n",
    "\n",
    "            if settings.central_group_name == \"RCOMe\" or settings.central_group_name == \"REt\":\n",
    "                print(METHYL_CSV)\n",
    "                fragment = add_model_methyl(CSV=METHYL_CSV, fragment=avg_frag,\n",
    "                                            settings=settings, radii=radii)\n",
    "\n",
    "            avg_frag.to_csv(settings.get_avg_frag_filename(), index=False)\n",
    "#             t1_avg_frag = time.time()\n",
    "#             avg_fragment_time = t1_avg_frag - t0_avg_frag\n",
    "\n",
    "#             t0_coordinate_df = time.time()\n",
    "#             df = aligned_fragments_df[aligned_fragments_df.label == \"-\"]\n",
    "\n",
    "#             coordinate_df = make_coordinate_df(df, settings, avg_frag, radii)\n",
    "\n",
    "#             t1_coordinate_df = time.time()\n",
    "#             coordinate_df_time = t1_coordinate_df - t0_coordinate_df\n",
    "\n",
    "#             print(central_group, contact_group, to_count_contact, alignment_time, avg_fragment_time, coordinate_df_time)\n",
    "\n",
    "            if write_times:\n",
    "                writer.writerow([central_group, contact_group, to_count_contact, coordinate_df_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = True\n",
    "write_time = False\n",
    "\n",
    "if rerun:\n",
    "    with open('../../results/density_comp_time.csv', 'a', newline='') as resultsfile:\n",
    "        if write_time:\n",
    "            writer = csv.writer(resultsfile)\n",
    "            writer.writerow(['central', 'contact', 'to_count', 'resolution', 'density_time'])\n",
    "\n",
    "        for central_group in central_groups:\n",
    "            for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "                datafile = \".\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "                result1 = \".\\\\results\\\\pairs\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5\\\\\"\\\n",
    "                          + central_group + \"_\" + contact_group + \"_aligned.csv\"\n",
    "\n",
    "                for resolution in resolutions:\n",
    "                    print(\"\\nCalculating density for central group: \", central_group, \" contact group: \", contact_group,\n",
    "                          \"resolution: \", str(round(resolution, 2)))\n",
    "\n",
    "                    t0 = time.time()\n",
    "\n",
    "                    settings = Settings(WORKDIR, datafile)\n",
    "                    settings.set_atom_to_count(to_count_contact)\n",
    "\n",
    "                    # resolution of the bins, in Angstrom\n",
    "                    settings.set_resolution(round(resolution, 2))\n",
    "                    \n",
    "                    df = pd.read_csv(settings.get_aligned_csv_filename())\n",
    "                    avg_frag = pd.read_csv(settings.get_avg_frag_filename())\n",
    "\n",
    "                    radii = Radii(RADII_CSV)\n",
    "                    \n",
    "                    # grab only the atoms that are in the contact groups\n",
    "                    df_central = df[df['label'] == '-']\n",
    "                    coordinate_df = make_coordinate_df(df_central, settings, avg_frag, radii)\n",
    "                    \n",
    "                    make_density_df(settings, coordinate_df)    \n",
    "\n",
    "                    t1 = time.time() - t0\n",
    "                    print(\"Duration: %.2f s.\" % t1)      \n",
    "                    \n",
    "                    if write_time:\n",
    "                        writer.writerow([central_group, contact_group, to_count_contact, round(resolution, 2), t1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/pre_density_comp_time.csv')\n",
    "\n",
    "df_count = pd.read_csv('results/amounts_structures.csv')\n",
    "df = pd.merge(df, df_count,  how='left', left_on=['central','contact'], right_on = ['central','contact'])\n",
    "\n",
    "real_coordinate_time = pd.read_csv('results/redo_coordinate_df.csv')\n",
    "\n",
    "real_coordinate_time.columns = ['central', 'contact', 'to_count', 'coordinate_df_real']\n",
    "df = pd.merge(df, real_coordinate_time,  how='left', left_on=['central','contact', 'to_count'], right_on = ['central','contact', 'to_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge with density comp times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "grouped = df.groupby(['central', 'contact', 'to_count'])\n",
    "\n",
    "id_df = grouped['density_time'].apply(lambda x: pd.Series(x.values)).unstack()\n",
    "id_df = id_df.reset_index()\n",
    "\n",
    "id_df.columns = ['central', 'contact', 'to_count', 'res15', 'res14', 'res13', 'res12', 'res11',\\\n",
    "                                                   'res10', 'res09', 'res08', 'res07', 'res06',\\\n",
    "                                                   'res05', 'res04', 'res03', 'res02', 'res01']\n",
    "display(id_df)\n",
    "\n",
    "df_pre = pd.read_csv('results/pre_density_comp_time.csv')\n",
    "\n",
    "df_total = pd.merge(df_pre, id_df, how='left', left_on=['contact','central', 'to_count'], right_on = ['contact','central', 'to_count'])\n",
    "display(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for central_group in central_groups:\n",
    "    print(central_group)\n",
    "    bars1 = df[df.central == central_group]['alignment']\n",
    "    bars2 = df[df.central == central_group]['avg_fragment']\n",
    "    bars3 = df[df.central == central_group]['coordinate_df']\n",
    "        \n",
    "    bar_width = 0.25  # the width of the bars\n",
    "    r1 = np.arange(len(bars1))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "\n",
    "    # make that plot\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(r1, bars1, bar_width, label='Alignment')\n",
    "    rects2 = ax.bar(r2, bars2, bar_width, label='avg_fragment')\n",
    "    rects3 = ax.bar(r3, bars3, bar_width, label='coordinate_df')\n",
    "\n",
    "    ax.set_xticks([r + bar_width for r in range(len(bars1))])\n",
    "    ax.set_xticklabels(df[df.central == central_group]['contact'])\n",
    "    \n",
    "    plt.title('Prep comp times ' + central_group)\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"results/figures/Prep_times_\" + central_group + \".svg\", format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df\n",
    "df[\"total\"] = df[\"alignment\"] + df[\"avg_fragment\"] + df[\"coordinate_df\"]\n",
    "df = df.sort_values(\"total\", ascending=False)\n",
    "\n",
    "df.to_hdf('ready_pre_density_comp.hdf', 'key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "r1 = []\n",
    "xtick_labels = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "    \n",
    "for _, row in df.iterrows():\n",
    "    bars1 = row['alignment']\n",
    "    bars2 = row['avg_fragment']\n",
    "    bars3 = row['coordinate_df']\n",
    "        \n",
    "    bar_width = 0.5  # the width of the bars\n",
    "    r1.append(i)\n",
    "\n",
    "    # make that plot\n",
    "    rects1 = plt.bar(i, bars1, bar_width, color=\"tab:blue\")\n",
    "    rects2 = plt.bar(i, bars2, bar_width, bottom=bars1, color=\"tab:orange\")\n",
    "    rects3 = plt.bar(i, bars3, bar_width, bottom=bars1+bars2, color=\"tab:green\")\n",
    "\n",
    "    xtick_labels.append(row[\"central\"] + \"-\" + row['contact'])\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "plt.xticks(r1, xtick_labels, rotation=90)\n",
    "\n",
    "plt.title('Prep comp times')\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Pair\")\n",
    "ax.set_ylabel(\"Computational time (s)\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Amount\")\n",
    "\n",
    "line = ax2.plot(range(len(df)), df[\"amount_structures\"], color=\"red\", label=\"no unique fragments\")\n",
    "\n",
    "plt.legend((rects1[0], rects2[0], rects3[0], line[0]), ('alignment', 'avg_fragment', 'coordinate_df', 'No. fragments'))\n",
    "\n",
    "plt.savefig(\"results/figures/Prep_times_total.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_df = pd.read_csv('results/coordinate_df_jit.csv')\n",
    "\n",
    "\n",
    "combined = pd.merge(jit_df, df,  how='left', left_on=['contact','central', 'to_count'], right_on = ['contact','central', 'to_count', ])\n",
    "\n",
    "combined[\"total_jit\"] = combined[\"alignment\"] + combined[\"avg_fragment\"] + combined[\"coordinate_df_jit\"]\n",
    "combined = combined.sort_values(\"total\", ascending=False)\n",
    "\n",
    "combined[\"diff\"] = combined[\"coordinate_df\"] - combined[\"coordinate_df_jit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r1 = []\n",
    "xtick_labels = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "    \n",
    "for _, row in combined.iterrows():\n",
    "    bars1 = row['alignment']\n",
    "    bars2 = row['avg_fragment']\n",
    "    bars3 = row['coordinate_df_jit']\n",
    "        \n",
    "    bar_width = 0.5  # the width of the bars\n",
    "    r1.append(i)\n",
    "\n",
    "    # make that plot\n",
    "    rects1 = plt.bar(i, bars1, bar_width, color=\"tab:blue\")\n",
    "    rects2 = plt.bar(i, bars2, bar_width, bottom=bars1, color=\"tab:orange\")\n",
    "    rects3 = plt.bar(i, bars3, bar_width, bottom=bars1+bars2, color=\"tab:green\")\n",
    "\n",
    "    xtick_labels.append(row[\"central\"] + \"-\" + row['contact'])\n",
    "    i+=1\n",
    "\n",
    "plt.xticks(r1, xtick_labels, rotation=90)\n",
    "\n",
    "plt.title('Prep comp times')\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Pair\")\n",
    "ax.set_ylabel(\"Computational time (s)\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Amount\")\n",
    "\n",
    "line = ax2.plot(range(len(df)), df[\"amount_structures\"], color=\"red\", label=\"no unique fragments\")\n",
    "\n",
    "plt.legend((rects1[0], rects2[0], rects3[0], line[0]), ('alignment', 'avg_fragment', 'coordinate_df_jit', 'No. fragments'))\n",
    "\n",
    "plt.savefig(\"results/figures/Prep_times_total.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r1 = []\n",
    "xtick_labels = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,15))\n",
    "    \n",
    "for _, row in df_total.iterrows():\n",
    "    bars1 = row['alignment']\n",
    "    bars2 = row['avg_fragment']\n",
    "    bars3 = row['coordinate_df']\n",
    "    bars4 = row['res01']\n",
    "    bars5 = row['res02']\n",
    "    bars6 = row['res03']\n",
    "    bars7 = row['res04']\n",
    "    bars8 = row['res05']\n",
    "        \n",
    "    bar_width = 0.5  # the width of the bars\n",
    "    r1.append(i)\n",
    "\n",
    "    bottom = 0\n",
    "    # make that plot\n",
    "    rects1 = plt.bar(i, bars1, bar_width, bottom=0, color=\"tab:blue\")\n",
    "    \n",
    "    bottom += bars1\n",
    "    rects2 = plt.bar(i, bars2, bar_width, bottom=bottom, color=\"tab:orange\")\n",
    "    \n",
    "    bottom += bars2\n",
    "    rects3 = plt.bar(i, bars3, bar_width, bottom=bottom, color=\"tab:green\")\n",
    "    \n",
    "    bottom += bars3\n",
    "    rects01 = plt.bar(i, bars4, bar_width, bottom=bottom, color='tab:red')\n",
    "    \n",
    "    bottom += bars4\n",
    "    rects02 = plt.bar(i, bars5, bar_width, bottom=bottom, color='tab:purple')\n",
    "    \n",
    "    bottom += bars5\n",
    "    rects03 = plt.bar(i, bars6, bar_width, bottom=bottom, color='tab:brown')\n",
    "    \n",
    "    bottom += bars6\n",
    "    rects04 = plt.bar(i, bars7, bar_width, bottom=bottom, color='tab:pink')\n",
    "    \n",
    "    bottom += bars7\n",
    "    rects05 = plt.bar(i, bars8, bar_width, bottom=bottom, color='tab:gray')\n",
    "    \n",
    "    xtick_labels.append(row[\"central\"] + \"-\" + row['contact'])\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "plt.xticks(r1, xtick_labels, rotation=90)\n",
    "\n",
    "plt.title('Computational times')\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Pair\")\n",
    "ax.set_ylabel(\"Computational time (s)\")\n",
    "\n",
    "# ax.set_ylim(0,100)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Amount\")\n",
    "# ax2.set_ylim(0, 600000)\n",
    "\n",
    "line = ax2.plot(range(len(df_total)), df_total[\"amount_structures\"], color=\"red\", label=\"no unique fragments\")\n",
    "\n",
    "plt.legend((rects1[0], rects2[0], rects3[0], rects01[0], rects02[0], rects03[0], rects04[0], rects05[0], line[0]),\n",
    "           ('alignment', 'avg_fragment', 'coordinate_df', 'density res 0.1', 'density res 0.2',\\\n",
    "            'density res 0.3', 'density res 0.4', 'density res 0.5', 'No. fragments'))\n",
    "\n",
    "plt.savefig(\"results/figures/comp_times_total.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['total_density'] = df_total.iloc[:, -15:].sum(axis=1)\n",
    "df_total['total'] = df_total['total_density'] + df_total['alignment'] + df_total['avg_fragment'] + df_total['coordinate_df']\n",
    "df_total = df_total.sort_values(\"total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r1 = []\n",
    "xtick_labels = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,12))\n",
    "    \n",
    "for _, row in df_total.iterrows():\n",
    "    bars1 = row['alignment']\n",
    "    bars2 = row['avg_fragment']\n",
    "    bars3 = row['coordinate_df']\n",
    "    bars4 = row['res01']\n",
    "    bars5 = row['res02']\n",
    "    bars6 = row['res03']\n",
    "    bars7 = row['res04']\n",
    "    bars8 = row['res05']\n",
    "        \n",
    "    bar_width = 0.5  # the width of the bars\n",
    "    r1.append(i)\n",
    "\n",
    "    bottom = 0\n",
    "    # make that plot\n",
    "    rects1 = plt.bar(i, bars1, bar_width, bottom=0, color=\"tab:blue\")\n",
    "    \n",
    "    bottom += bars1\n",
    "    rects2 = plt.bar(i, bars2, bar_width, bottom=bottom, color=\"tab:orange\")\n",
    "    \n",
    "    bottom += bars2\n",
    "    rects3 = plt.bar(i, bars3, bar_width, bottom=bottom, color=\"tab:green\")\n",
    "    \n",
    "    bottom += bars3\n",
    "    rects01 = plt.bar(i, bars4, bar_width, bottom=bottom, color='tab:red')\n",
    "    \n",
    "    bottom += bars4\n",
    "    rects02 = plt.bar(i, bars5, bar_width, bottom=bottom, color='tab:purple')\n",
    "    \n",
    "    bottom += bars5\n",
    "    rects03 = plt.bar(i, bars6, bar_width, bottom=bottom, color='tab:brown')\n",
    "    \n",
    "    bottom += bars6\n",
    "    rects04 = plt.bar(i, bars7, bar_width, bottom=bottom, color='tab:pink')\n",
    "    \n",
    "    bottom += bars7\n",
    "    rects05 = plt.bar(i, bars8, bar_width, bottom=bottom, color='tab:gray')\n",
    "    \n",
    "    xtick_labels.append(row[\"central\"] + \"-\" + row['contact'])\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "plt.xticks(r1, xtick_labels, rotation=90)\n",
    "\n",
    "plt.title('Computational times')\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Pair\")\n",
    "ax.set_ylabel(\"Computational time (s)\")\n",
    "\n",
    "# ax.set_ylim(0,100)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(\"Amount\")\n",
    "# ax2.set_ylim(0, 600000)\n",
    "\n",
    "line = ax2.plot(range(len(df_total)), df_total[\"amount_structures\"], color=\"gold\", label=\"no unique fragments\")\n",
    "\n",
    "plt.legend((rects1[0], rects2[0], rects3[0], rects01[0], rects02[0], rects03[0], rects04[0], rects05[0], line[0]),\n",
    "           ('alignment', 'avg_fragment', 'coordinate_df', 'density res 0.1', 'density res 0.2',\\\n",
    "            'density res 0.3', 'density res 0.4', 'density res 0.5', 'No. fragments'))\n",
    "\n",
    "plt.savefig(\"results/figures/comp_times_total.svg\", format=\"svg\", bbox_inches='tight')\n",
    "plt.savefig(\"results/figures/comp_times_total.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
