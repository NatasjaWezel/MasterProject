{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# allows for automatic reloading of imports and makes it unncessecary to restart the kernel\n",
    "# whenever a function is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from classes.Settings import Settings\n",
    "from helpers.geometry_helpers import make_coordinate_df\n",
    "from calc_density_4 import count_points_per_square\n",
    "\n",
    "from helpers.plot_functions import plot_density, plot_fragment_colored, plot_vdw_spheres\n",
    "from helpers.density_helpers import prepare_df, find_available_volume\n",
    "from helpers.geometry_helpers import (make_coordinate_df,\n",
    "                                      get_vdw_distance_contact)\n",
    "\n",
    "\n",
    "central_groups = [\"RCOMe\", \"RNO2\", \"ArCI\", \"NO3\", \"RC6F5\", \"H2O\", \"RC6H5\"]\n",
    "contact_groups = [\"CF\", \"RCN\", \"R2CO\", \"XH\", \"XH\", \"CCH3\", \"C2CH2\", \"RC6H5\", \"ArCH\"]  #\n",
    "to_count =       [\"F\",   \"N\",    \"O\",   \"H\", \"O\",  \"H\",     \"H\", \"centroid\", \"H\"] #, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_density_plot(avg_fragment, density_df, settings):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax: Axes3D = fig.add_subplot(111, projection='3d')\n",
    "    title_string = f\"{settings.central_group_name}-{settings.contact_group_name} resolution: {settings.resolution: .2f}\\\n",
    "                     Interacting part of contact group: {to_count_contact}\"\n",
    "    ax.set_title(title_string.replace(\"\", \" \"))\n",
    "    \n",
    "    ax = plot_fragment_colored(ax, avg_fragment)\n",
    "\n",
    "    p, ax = plot_density(ax=ax, df=density_df, settings=settings)\n",
    "\n",
    "    ax.set_title(\"4D density plot\\n Resolution: \" + str(settings.resolution))\n",
    "    \n",
    "    fig.colorbar(p)\n",
    "    plt.savefig('results/directionality_tests/' + settings.central_group_name  + \"/\" + settings.central_group_name + \"_\" + settings.contact_group_name + \"_1_resolution_\" + str(settings.resolution) + '.png')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_clusters(density_df, amount_of_clusters):\n",
    "    to_cluster_df = density_df[density_df['to_cluster']]\n",
    "    \n",
    "    X = np.transpose(np.array([to_cluster_df.x_center, to_cluster_df.y_center, to_cluster_df.z_center]))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=amount_of_clusters, random_state=1)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    density_df.loc[density_df['to_cluster'], \"cluster\"] = kmeans.labels_\n",
    "    \n",
    "    return density_df, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bins_to_cluster(settings, density_df, fraction):    \n",
    "    density_df[\"x_center\"] = density_df.xstart + 0.5 * settings.resolution\n",
    "    density_df[\"y_center\"] = density_df.ystart + 0.5 * settings.resolution\n",
    "    density_df[\"z_center\"] = density_df.zstart + 0.5 * settings.resolution\n",
    "    \n",
    "    # normalize\n",
    "    density_df.loc[:, settings.to_count_contact + \"_normalized\"] =\\\n",
    "        density_df[settings.to_count_contact] / density_df[settings.to_count_contact].sum()\n",
    "\n",
    "    # reset cluster color for when you run this cell again\n",
    "    density_df[\"cluster_color\"] = np.nan\n",
    "    \n",
    "    # set a threshold as to determine will belong to a cluster and which ones won't\n",
    "    # get the upper kwartant\n",
    "    max_bin = density_df[settings.to_count_contact].max()\n",
    "    threshold = max_bin * fraction\n",
    "    print(\"Threshold k-means:\", threshold, \"max_bin:\", max_bin, \"with fraction:\", fraction)\n",
    "  \n",
    "    density_df[\"cluster\"] = np.nan\n",
    "    density_df[\"to_cluster\"] = False\n",
    "    density_df.loc[density_df[settings.to_count_contact] > threshold, 'to_cluster'] = True\n",
    "    \n",
    "    return density_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reduce(lst):\n",
    "    if len(lst) == 1:\n",
    "        return lst[0]\n",
    "    elif len(lst) == 0:\n",
    "        return []\n",
    "    \n",
    "    reduced_list = lst[0]\n",
    "    for x in lst[1:]:\n",
    "        reduced_list = reduced_list.append(x)\n",
    "\n",
    "    reduced_list = reduced_list.drop_duplicates(keep='first')\n",
    "    return reduced_list\n",
    "\n",
    "    \n",
    "def fill_holes(df, radius, column):\n",
    "    amount = settings.to_count_contact\n",
    "    unique_clusters = df.cluster.dropna().unique()\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        # get all bins in the cluster\n",
    "\n",
    "        cluster_indices = df.index[(df[column] == cluster_id)]   \n",
    "        boundary_indices = []\n",
    "    \n",
    "        for _, row in df.loc[cluster_indices, :].iterrows():\n",
    "\n",
    "            # get empty bins around cluster bins\n",
    "            boundary_index = df.index[((df[column].isna()) &\n",
    "                                         (np.sqrt((df.x_center - row.x_center)**2 +\n",
    "                                            (df.y_center - row.y_center)**2 +\n",
    "                                            (df.z_center - row.z_center)**2) <= radius))]\n",
    "            \n",
    "            boundary_indices.append(boundary_index)\n",
    "        \n",
    "        boundary_index = my_reduce(boundary_indices)\n",
    "        \n",
    "        \n",
    "        while len(boundary_index) > 0:\n",
    "            new_cluster_bins = []\n",
    "            # count bins around these bins\n",
    "            for i, emptyrow in df.loc[boundary_index, :].iterrows():\n",
    "                index = df.index[((df[column] == cluster_id) & \n",
    "                                   (np.sqrt((df.x_center - emptyrow.x_center)**2 +\n",
    "                                            (df.y_center - emptyrow.y_center)**2 +\n",
    "                                            (df.z_center - emptyrow.z_center)**2) <= radius))]\n",
    "\n",
    "                # if 3 or more neighbors are in the cluster, append\n",
    "                if len(index) >= 3:\n",
    "#                     print('Found a hole!')\n",
    "                    df.loc[i, column] = cluster_id\n",
    "                    \n",
    "                    new_cluster_bins.append(i)\n",
    "                                \n",
    "            print('Added another:', len(new_cluster_bins))\n",
    "            \n",
    "            boundary_indices = []\n",
    "            # check around the newly filled holes for boundary bins\n",
    "            for _, row in df.loc[new_cluster_bins, :].iterrows():\n",
    "\n",
    "                # get empty bins around cluster bins\n",
    "                boundary_index = df.index[((df[column].isna()) &\n",
    "                                             (np.sqrt((df.x_center - row.x_center)**2 +\n",
    "                                            (df.y_center - row.y_center)**2 +\n",
    "                                            (df.z_center - row.z_center)**2) <= radius))]\n",
    "\n",
    "                boundary_indices.append(boundary_index)\n",
    "        \n",
    "            boundary_index = my_reduce(boundary_indices)\n",
    "            print('Dit is de lijst van alex:', len(boundary_index))\n",
    "                                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_clusters(df, new_indices, fraction, cluster_id, column_name, settings):\n",
    "    # always look only 1 bin further\n",
    "    radius = settings.resolution\n",
    "    \n",
    "    # while new bins that belong to the cluster are found, keep expanding\n",
    "    while new_indices:\n",
    "        old_length = len(df[df[column_name] == cluster_id])\n",
    "\n",
    "        indices = []\n",
    "\n",
    "        for new_index in new_indices:\n",
    "\n",
    "            for _, row in df.loc[new_index, :].iterrows():\n",
    "                index = df.index[((df[column_name].isna()) &\n",
    "                                 (df.x_center >= row.x_center - radius) & (df.x_center <= row.x_center + radius) & \n",
    "                                 (df.y_center >= row.y_center - radius) & (df.y_center <= row.y_center + radius) &\n",
    "                                 (df.z_center >= row.z_center - radius) & (df.z_center <= row.z_center + radius) &\n",
    "                                 (df[settings.to_count_contact] > fraction))]\n",
    "\n",
    "                indices.append(index)\n",
    "\n",
    "                df.loc[index, column_name] = cluster_id\n",
    "\n",
    "        new_indices = indices\n",
    "        \n",
    "        print(f\"Added {len(indices)} new bins\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster0(df, settings, recluster_frac):\n",
    "    amount = settings.to_count_contact\n",
    "    \n",
    "    unique_clusters = df.cluster.dropna().unique()\n",
    "\n",
    "    df[\"new_cluster0\"] = np.nan\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        \n",
    "        # local maximum\n",
    "        max_bin = df[df.cluster == cluster_id][amount].max()\n",
    "        \n",
    "        fraction = max_bin * recluster_frac\n",
    "        print(\"Cluster id: \" + str(cluster_id), \" max bin: \" + str(max_bin) + \" fraction for this bin: \", fraction)\n",
    "        \n",
    "        new_indices = []\n",
    "        # starting bin is only fullest bin(s)\n",
    "        index = df.index[((df.cluster == cluster_id) & (df[amount] == max_bin))]\n",
    "        df.loc[index, \"new_cluster0\"] = cluster_id      \n",
    "        \n",
    "        new_indices.append(index)\n",
    "                \n",
    "        # expand clusters\n",
    "        df = expand_clusters(df, new_indices, fraction, cluster_id, 'new_cluster0', settings)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster1(df, settings, recluster_frac):\n",
    "    amount = settings.to_count_contact\n",
    "    \n",
    "    unique_clusters = df.cluster.dropna().unique()\n",
    "\n",
    "    df[\"new_cluster1\"] = np.nan\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        \n",
    "        # local maximum\n",
    "        max_bin = df[df.cluster == cluster_id][amount].max()      \n",
    "        fraction = max_bin * recluster_frac\n",
    "        \n",
    "        print(\"Cluster id: \" + str(cluster_id), \" max bin: \" + str(max_bin) + \" fraction for this bin: \", fraction)\n",
    "        \n",
    "        new_indices = []\n",
    "        # put bins from K-means that are fuller then LOCAL threshold \n",
    "        index = df.index[((df.cluster == cluster_id) & (df[amount] >= fraction))]\n",
    "        df.loc[index, \"new_cluster1\"] = cluster_id      \n",
    "        \n",
    "        new_indices.append(index)\n",
    "                                    \n",
    "        # expand clusters\n",
    "        df = expand_clusters(df, new_indices, fraction, cluster_id, 'new_cluster1', settings)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster2(df, settings, recluster_frac):\n",
    "    amount = settings.to_count_contact\n",
    "    \n",
    "    unique_clusters = df.cluster.dropna().unique()\n",
    "    \n",
    "    # global maximum\n",
    "    global_max = df[amount].max()\n",
    "    fraction = global_max * recluster_frac\n",
    "\n",
    "    df[\"new_cluster2\"] = np.nan\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        \n",
    "        max_bin = df[df.cluster == cluster_id][amount].max()\n",
    "        print(\"Cluster id: \" + str(cluster_id), \" max bin: \" + str(max_bin) + \" fraction for this bin: \", fraction)\n",
    "        \n",
    "        new_indices = []\n",
    "        # start only with fullest bin per cluster\n",
    "        index = df.index[((df.cluster == cluster_id) & (df[amount] == max_bin))]\n",
    "        df.loc[index, \"new_cluster2\"] = cluster_id      \n",
    "        \n",
    "        new_indices.append(index)\n",
    "                    \n",
    "        # expand clusters\n",
    "        df = expand_clusters(df, new_indices, fraction, cluster_id, 'new_cluster2', settings)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster3(df, settings, recluster_frac):\n",
    "    amount = settings.to_count_contact\n",
    "    \n",
    "    unique_clusters = df.cluster.dropna().unique()\n",
    "    \n",
    "    # global maximum\n",
    "    global_max = df[amount].max()\n",
    "    fraction = global_max * recluster_frac\n",
    "\n",
    "    df[\"new_cluster3\"] = np.nan\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        \n",
    "        max_bin = df[df.cluster == cluster_id][amount].max()\n",
    "        print(\"Cluster id: \" + str(cluster_id), \" max bin: \" + str(max_bin) + \" fraction for this bin: \", fraction)\n",
    "        \n",
    "        new_indices = []\n",
    "        # start with points from KMEANS that are fuller then the TRESHOLD\n",
    "        index = df.index[((df.cluster == cluster_id) & (df[amount] >= fraction))]\n",
    "        df.loc[index, \"new_cluster3\"] = cluster_id      \n",
    "        \n",
    "        new_indices.append(index)\n",
    "                    \n",
    "        # expand clusters\n",
    "        df = expand_clusters(df, new_indices, fraction, cluster_id, 'new_cluster3', settings)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_directionality(settings, density_df, k, kmeans_frac, recluster_frac):\n",
    "    cluster_count = 0\n",
    "\n",
    "    # work only with bins that are >0.25*maximum full\n",
    "    density_df = find_bins_to_cluster(settings=settings, density_df=density_df, fraction=kmeans_frac)\n",
    "\n",
    "    # calc for each bin in what cluster it belongs\n",
    "    density_df, centroids = calc_clusters(density_df, k)\n",
    "    density_df.drop(columns=[\"to_cluster\"])\n",
    "    \n",
    "    # find the volume of the central group\n",
    "    tolerance = 0.5\n",
    "\n",
    "    df = pd.read_csv(settings.get_kabsch_aligned_csv_filename())\n",
    "    avg_fragment = pd.read_csv(settings.get_avg_frag_filename())\n",
    "\n",
    "    coordinate_df = make_coordinate_df(df, settings, avg_fragment)\n",
    "    \n",
    "    contact_group_radius = get_vdw_distance_contact(df, settings)\n",
    "    available_volume = find_available_volume(avg_fragment=avg_fragment, extra=(tolerance + contact_group_radius))\n",
    "    \n",
    "#     print(\"\\nRecluster method 0\")\n",
    "#     density_df = recluster0(density_df, settings, recluster_frac)\n",
    "\n",
    "#     print(\"\\nRecluster method 1\")\n",
    "#     density_df = recluster1(density_df, settings, recluster_frac)\n",
    "\n",
    "#     print(\"\\nRecluster method 2\")\n",
    "#     density_df = recluster2(density_df, settings, recluster_frac)\n",
    "    \n",
    "    print(\"\\nRecluster method 3\")\n",
    "    density_df = recluster3(density_df, settings, recluster_frac)\n",
    "        \n",
    "    return density_df, centroids, available_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_directionality(avg_fragment, df, column, settings, available_volume, plt_name, kfrac):\n",
    "    colors = [\"red\", \"green\", \"blue\", \"purple\", \"yellow\", \"pink\", \"orange\", \"grey\"]\n",
    "    \n",
    "    df[\"cluster_color\"] = \"grey\"\n",
    "\n",
    "    df.loc[df[column].notna(), \"cluster_color\"] = [colors[int(i)] for i in list(df.loc[df[column].notna(), column])]\n",
    "    df = df[df[settings.to_count_contact + \"_normalized\"] > 0]\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax: Axes3D = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    rest = df[df.cluster_color != \"grey\"]\n",
    "    \n",
    "    clusters = df[column].dropna().unique()\n",
    "    print(clusters)\n",
    "    k = len(clusters)\n",
    "    \n",
    "    txt = \"Available volume: + \" + str(available_volume) + \"\\nClusters: \" + str(k) + \"\\n\"\n",
    "    for cluster_id in clusters:\n",
    "        points = df[df[column] == cluster_id]\n",
    "        firstpoint = points.iloc[0]\n",
    "        volume = len(points) * settings.resolution**3\n",
    "        fraction = points[settings.to_count_contact + \"_normalized\"].sum()\n",
    "        directionality = fraction/volume * available_volume\n",
    "        \n",
    "        with open('results/single_directionality.csv', 'a', newline='') as results:\n",
    "            writer = csv.writer(results)\n",
    "            writer.writerow([settings.central_group_name, settings.contact_group_name, settings.to_count_contact, \n",
    "                             settings.resolution, kfrac, column, directionality])\n",
    "        \n",
    "        ax.scatter(firstpoint.x_center, firstpoint.y_center, firstpoint.z_center,\\\n",
    "                    label=\"Cluster: \" + str(cluster_id) + \" Directionality:\" + str(round(directionality, 2)),\\\n",
    "                    color=firstpoint.cluster_color)\n",
    "        \n",
    "        txt += 'id: ' + str(cluster_id) + ' vol: ' + str(round(volume,2)) + ' frac: ' + str(round(fraction,2)) + \"\\n\"\n",
    "            \n",
    "    fig.text(.05,.05,txt)\n",
    "    \n",
    "    ax.scatter(list(rest.x_center), list(rest.y_center), list(rest.z_center),\n",
    "               color=list(rest.cluster_color))\n",
    "    \n",
    "    # plot the average fragment\n",
    "    ax = plot_fragment_colored(ax, avg_fragment)\n",
    "\n",
    "    ax.set_title(\"Clusters \" + settings.central_group_name + \"-\" + settings.contact_group_name + \", resolution: \" + str(settings.resolution) + \"\\n\" + column)\n",
    "    \n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-6, 6)\n",
    "    \n",
    "    ax.set_xlabel(\"X coordinate\")\n",
    "    ax.set_ylabel(\"Y coordinate\")\n",
    "    \n",
    "    ax.legend(fontsize='x-small')\n",
    "    \n",
    "    elev = 89\n",
    "    azim = -89\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.savefig(plt_name)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for resolution 0.25\n",
    "cluster_amount= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_name(settings, column, cluster_amount, filledholes=False):\n",
    "    k = cluster_amount\n",
    "    if filledholes:\n",
    "        string = f\"results/single_cluster_directionality/{settings.central_group_name}/{settings.central_group_name}_\\\n",
    "                {settings.contact_group_name}_{settings.to_count_contact}_k{k}_resolution_{settings.resolution: .2f}\\\n",
    "                _{column}kfrac_{kfrac: .2f}_refrac_{recluster_frac: .2f}_filledholes.png\"\n",
    "    else:\n",
    "        string = f\"results/single_cluster_directionality/{settings.central_group_name}/{settings.central_group_name}_\\\n",
    "                  {settings.contact_group_name}_{settings.to_count_contact}_k{k}_resolution_{settings.resolution: .2f}\\\n",
    "                  _{column}kfrac_{kfrac: .2f}_refrac_{recluster_frac: .2f}.png\"\n",
    "            \n",
    "    return string.replace(\" \", \"\")\n",
    "\n",
    "def get_cluster_plot_name(settings, column, cluster_amount):\n",
    "    k = cluster_amount\n",
    "\n",
    "    string = f'results/single_cluster_directionality/{settings.central_group_name}/{settings.central_group_name}_\\\n",
    "             {settings.contact_group_name}_{settings.to_count_contact}_k{k}_resolution_{settings.resolution: .2f}\\\n",
    "             _{column}_kfrac{kfrac: .2f}.png'\n",
    "    \n",
    "    return string.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "central_groups = [\"RCOMe\", \"RNO2\", \"ArCI\", \"NO3\", \"RC6F5\", \"H2O\", \"RC6H5\"]\n",
    "contact_groups = [\"CF\", \"RCN\", \"R2CO\", \"XH\", \"XH\", \"CCH3\", \"C2CH2\", \"RC6H5\", \"ArCH\"]  #\n",
    "to_count =       [\"F\",   \"N\",    \"O\",   \"H\", \"O\",  \"H\",     \"H\", \"centroid\", \"H\"] #, \n",
    "\n",
    "if not os.path.exists('results/single_cluster_directionality/'):\n",
    "    os.mkdir('results/single_cluster_directionality/')\n",
    "\n",
    "kfrac = 0.25\n",
    "recluster_frac = 0.25\n",
    "\n",
    "resolution = 0.50\n",
    "\n",
    "for central in central_groups:\n",
    "    for contact, to_count_contact in zip(contact_groups, to_count):\n",
    "        if not os.path.exists('results/single_cluster_directionality/' + central + \"/\"):\n",
    "            os.mkdir('results/single_cluster_directionality/' + central + \"/\")\n",
    "        \n",
    "        print(central, contact)\n",
    "        if central == \"RC6H5\" and contact == \"RC6H5\":\n",
    "            break\n",
    "            \n",
    "        filename = \".\\\\results\\\\\" + central + \"\\\\\" + central + \"_\" + contact + \"_vdw.5\" + \"\\\\\" + central + \"_\" + contact + \"_vdw.5_aligned.csv\"\n",
    "        settings = Settings(filename)\n",
    "        settings.set_atom_to_count(to_count_contact)\n",
    "        settings.set_resolution(round(resolution, 2))\n",
    "        \n",
    "        avg_fragment = pd.read_csv(settings.get_avg_frag_filename())\n",
    "        density_df = pd.read_hdf(settings.get_density_df_filename(), settings.get_density_df_key())\n",
    "        print(settings.get_density_df_filename(), settings.get_density_df_key())\n",
    "        \n",
    "        maximum = density_df[to_count_contact].max()\n",
    "        print(density_df[density_df[to_count_contact] == maximum])\n",
    "         \n",
    "#         make_density_plot(avg_fragment, density_df, settings)\n",
    "\n",
    "        density_df, centroids, V_available = calc_directionality(settings=settings,\n",
    "                                                                  density_df=density_df,\n",
    "                                                                  k=cluster_amount, \n",
    "                                                                  kmeans_frac=kfrac,\n",
    "                                                                  recluster_frac=recluster_frac)\n",
    "\n",
    "        print(\"Available volume:\", V_available)\n",
    "        \n",
    "        # cluster\n",
    "        plt_name = get_cluster_plot_name(settings, 'cluster', cluster_amount)\n",
    "        show_directionality(avg_fragment, density_df, 'cluster', settings, V_available, plt_name, kfrac)\n",
    "                \n",
    "        # recluster in method 3 and fill the holes\n",
    "        plt_name = get_plot_name(settings, 'new_cluster3', cluster_amount)       \n",
    "        density_df_filled_cluster = fill_holes(copy.deepcopy(density_df), settings.resolution, column='new_cluster3')\n",
    "        \n",
    "        plt_name = get_plot_name(settings, 'new_cluster3', cluster_amount, filledholes=True)\n",
    "        show_directionality(avg_fragment, density_df_filled_cluster, 'new_cluster3', settings, V_available, plt_name, kfrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
