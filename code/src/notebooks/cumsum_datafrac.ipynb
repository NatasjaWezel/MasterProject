{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative sums\n",
    "The research question for this notebook is: \"What parameters can we best use to say something about directionality?\"\n",
    "\n",
    "We sort the bins based on how full they are. The y-axis will be the cumulative sum of this data fraction. The x-axis will be the percentage of the free volume in which this data is. \n",
    "\n",
    "The hypothesis is that this will be a straight line for non-directional interaction between pairs and would be steeper for more directional interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..//scripts//helpers//')\n",
    "sys.path.append('..//scripts//classes//')\n",
    "sys.path.append('..//scripts//constants//')\n",
    "\n",
    "from density_helpers import find_available_volume, prepare_df\n",
    "from geometry_helpers import (make_coordinate_df)\n",
    "from Settings import Settings, Radii\n",
    "\n",
    "from paths import WORKDIR, RADII_CSV\n",
    "\n",
    "central_groups = [\"RCOMe\", \"RNO2\", \"ArCI\", \"NO3\", \"RC6F5\", \"H2O\", \"RC6H5\"]\n",
    "contact_groups = [\"ArCH\", \"C2CH2\", \"CCH3\", \"CF\", \"R2CO\", \"RC6H5\", \"RCN\", \"XH\", \"XH\"]\n",
    "to_count =       [\"H\",    \"H\",      \"H\",   \"F\", \"O\",     \"centroid\", \"N\", \"H\", \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make volume csv if not exists\n",
    "import os\n",
    "import csv\n",
    "\n",
    "tolerance = 0.5\n",
    "\n",
    "if not os.path.exists('../../results/volumes_free.csv'):\n",
    "    with open('../../results/volumes_free.csv', 'w', newline='') as freevolumesfile:\n",
    "        csvwriter = csv.writer(freevolumesfile)\n",
    "        csvwriter.writerow(['central', 'contact', 'to_count', 'volume'])\n",
    "\n",
    "        for central_group in central_groups:   \n",
    "            for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "                if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "                    continue\n",
    "                \n",
    "                datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "\n",
    "                settings = Settings('..\\\\..', datafile, datafile)\n",
    "                settings.set_atom_to_count(to_count_contact)\n",
    "\n",
    "                ############ find out volume of the central group \n",
    "                aligned_df = pd.read_csv(settings.get_aligned_csv_filename(), header=0)\n",
    "                avg_fragment = pd.read_csv(settings.get_avg_frag_filename())\n",
    "\n",
    "                contact_group_radius = Radii(RADII_CSV).get_vdw_distance_contact(aligned_df, settings)\n",
    "                volume = find_available_volume(avg_fragment=avg_fragment, extra=(tolerance + contact_group_radius))\n",
    "                \n",
    "                csvwriter.writerow([central_group, contact_group, to_count_contact, volume])\n",
    "                \n",
    "                print(f\"Free Volume {central_group}, {contact_group} ({to_count_contact}) is {volume}\")\n",
    "                \n",
    "                \n",
    "if not os.path.exists('../../results/volumes_total.csv'):\n",
    "    with open('../../results/volumes_total.csv', 'w', newline='') as freevolumesfile:\n",
    "        csvwriter = csv.writer(freevolumesfile)\n",
    "        csvwriter.writerow(['central', 'contact', 'to_count', 'volume'])\n",
    "\n",
    "        for central_group in central_groups:   \n",
    "            for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "                if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "                    continue\n",
    "            \n",
    "                datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "\n",
    "                settings = Settings('..\\\\..', datafile, datafile)\n",
    "                settings.set_atom_to_count(to_count_contact)\n",
    "\n",
    "                ############ find out volume of the central group \n",
    "                aligned_df = pd.read_csv(settings.get_aligned_csv_filename(), header=0)\n",
    "                avg_fragment = pd.read_csv(settings.get_avg_frag_filename())\n",
    "\n",
    "                contact_group_radius = Radii(RADII_CSV).get_vdw_distance_contact(aligned_df, settings)\n",
    "                volume = find_available_volume(avg_fragment=avg_fragment, extra=(tolerance + contact_group_radius), total=True)\n",
    "                \n",
    "                csvwriter.writerow([central_group, contact_group, to_count_contact, volume])\n",
    "                \n",
    "                print(f\"Total Volume {central_group}, {contact_group} ({to_count_contact}) is {volume}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes_free = pd.read_csv('../../results/volumes_free.csv')\n",
    "volumes_total = pd.read_csv('../../results/volumes_total.csv')\n",
    "\n",
    "display(volumes_free)\n",
    "display(volumes_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(central_group, contact_group, to_count_contact, resolution):\n",
    "    datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "\n",
    "    settings = Settings('..\\\\..', datafile, datafile)\n",
    "    settings.set_atom_to_count(to_count_contact)\n",
    "    settings.set_resolution(resolution)\n",
    "\n",
    "    density_df = pd.read_hdf(settings.get_density_df_filename(), settings.get_density_df_key())\n",
    "\n",
    "    density_df['datafrac_normalized'] = density_df[to_count_contact] / density_df[to_count_contact].sum()\n",
    "    \n",
    "    # sort from max bin to min bin\n",
    "    density_df = density_df.sort_values(by=to_count_contact, ascending=False).reset_index()\n",
    "    \n",
    "    density_df['cum_data'] = density_df[\"datafrac_normalized\"].cumsum()\n",
    "    density_df['cum_vol'] = density_df.index * resolution**3\n",
    "    \n",
    "    return density_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cum_vol(density_df, volumes):\n",
    "    free_volume = volumes.loc[(volumes.central == central_group) & (volumes.contact == contact_group) & (volumes.to_count == to_count_contact), 'volume'].item()  \n",
    "    \n",
    "    density_df = density_df[density_df['cum_vol'] <= free_volume].copy()\n",
    "    density_df['cum_vol'] = density_df['cum_vol'] / free_volume\n",
    "    \n",
    "    return density_df\n",
    "\n",
    "\n",
    "def make_plot(density_df):    \n",
    "    cluster_frac = 0.25\n",
    "    threshold = density_df.datafrac_normalized.max() * cluster_frac\n",
    "    in_cluster = density_df[density_df.datafrac_normalized >= threshold]\n",
    "            \n",
    "    ax = plt.gca()\n",
    "    color = next(ax._get_lines.prop_cycler)['color']\n",
    "    \n",
    "    plt.plot(density_df['cum_vol'], density_df['cum_data'], color=color, label=f\"{central_group}--{contact_group} ({to_count_contact})\")\n",
    "    plt.scatter(in_cluster['cum_vol'], in_cluster['cum_data'], color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resolution = 0.50\n",
    "\n",
    "for central_group in central_groups:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.title(\"Cumulative datafraction \" + central_group)\n",
    "    \n",
    "    for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "        \n",
    "        if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "            continue\n",
    "        \n",
    "        density_df = get_data(central_group, contact_group, to_count_contact, resolution)\n",
    "        density_df = normalize_cum_vol(density_df, volumes_free)\n",
    "        make_plot(density_df)\n",
    "        \n",
    "    plt.ylabel(\"Cumulative datafraction\")\n",
    "    plt.xlabel(\"Cumulative fraction of free volume\")\n",
    "#     plt.xscale('log')\n",
    "#     plt.yscale('log')\n",
    "        \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'../../results/cumsums/cumsum_data_and_volume_{central_group}_res{resolution}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resolution = 0.50\n",
    "\n",
    "for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.title(\"Cumulative datafraction, contact group: \" + contact_group)\n",
    "\n",
    "    for central_group in central_groups:\n",
    "            \n",
    "        if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "            continue\n",
    "\n",
    "        density_df = get_data(central_group, contact_group, to_count_contact, resolution)\n",
    "        density_df = normalize_cum_vol(density_df, volumes_free)\n",
    "        make_plot(density_df)\n",
    "\n",
    "    plt.ylabel(\"(Log of) Cumulative datafraction\")\n",
    "    plt.xlabel(\"(Log of) Cumulative fraction of free volume\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'../../results/cumsums/cumsum_data_and_volume_per_contact_{contact_group}_res{resolution}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the plots\n",
    "We see that some of the lines do not get to to the datafraction of 1.0. What is going on there?\n",
    "\n",
    "Is there a way to show how we got the directionality in these plots?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_directionalities(cluster_frac, resolution):\n",
    "    directionalities = []\n",
    "    \n",
    "    for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "        for central_group in central_groups:\n",
    "            if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "                continue\n",
    "    \n",
    "            datafile = \"..\\\\data\\\\\" + central_group + \"\\\\\" + central_group + \"_\" + contact_group + \"_vdw.5.cor\"\n",
    "\n",
    "            settings = Settings('..\\..', datafile, datafile)\n",
    "            settings.set_atom_to_count(to_count_contact)\n",
    "            settings.set_resolution(resolution)\n",
    "\n",
    "            density_df = pd.read_hdf(settings.get_density_df_filename(), settings.get_density_df_key())\n",
    "\n",
    "            density_df['datafrac_normalized'] = density_df[to_count_contact] / density_df[to_count_contact].sum()\n",
    "            \n",
    "            threshold = density_df.datafrac_normalized.max() * cluster_frac\n",
    "            in_cluster = density_df[density_df.datafrac_normalized >= threshold]\n",
    "            \n",
    "            Vavailable = volumes.loc[(volumes.central == central_group) & (volumes.contact == contact_group) & (volumes.to_count == to_count_contact), 'volume'].item()  \n",
    "\n",
    "            datafrac = in_cluster.datafrac_normalized.sum()\n",
    "            Vcluster = len(in_cluster) * resolution**3\n",
    "            \n",
    "            directionality = datafrac / Vcluster * Vavailable\n",
    "            directionalities.append(directionality)\n",
    "            \n",
    "    return directionalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directionalities = calc_all_directionalities(0.25, 0.5)\n",
    "i = -1\n",
    "for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "    for central_group in central_groups:\n",
    "        if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "            continue\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "        print(contact_group, central_group, round(directionalities[i], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting logarithmic functions\n",
    "\n",
    "$scipy.optimize.curve\\_fit(lambda t, a, b: a + b * numpy.log(t)$,  x,  y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small test\n",
    "x = np.array([1, 7, 20, 50, 79])\n",
    "y = np.array([10, 19, 30, 35, 51])\n",
    "sp.optimize.curve_fit(lambda t,a,b: a+b*np.log(t),  x,  y)\n",
    "\n",
    "# (array([ 6.61867467,  8.46295606]), \n",
    "#  array([[ 28.15948002,  -7.89609542],\n",
    "#         [ -7.89609542,   2.9857172 ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resolution = 0.50\n",
    "\n",
    "for central_group in central_groups:    \n",
    "    for to_count_contact, contact_group in zip(to_count, contact_groups):\n",
    "        \n",
    "        if central_group == \"RC6H5\" and contact_group == \"RC6H5\" or central_group == \"RC6H5\" and contact_group == \"ArCH\":\n",
    "            continue\n",
    "        \n",
    "        density_df = get_data(central_group, contact_group, to_count_contact, resolution)        \n",
    "        density_df = normalize_cum_vol(density_df, volumes_free)\n",
    "        \n",
    "        print(sp.optimize.curve_fit(lambda t, a, b: a + b * np.log(t), density_df['cum_vol'], density_df['cum_data']))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to compare directionality-sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.25\n",
    "res = 0.5\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('Test')\n",
    "gs = fig.add_gridspec(1, 4)\n",
    "plt.subplots_adjust(left=0.15, bottom=0.2)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0:3])\n",
    "ax1.hist(directionalities, bins=50, rwidth=0.85)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 3])\n",
    "x = [0] * len(directionalities)\n",
    "\n",
    "scatter2 = ax2.scatter(x, directionalities)\n",
    "ax2.set_xlim(-10, 10)\n",
    "ax2.axes.get_xaxis().set_visible(False)  # remove the x-axis and its ticks\n",
    "ax2.set_aspect(5, adjustable='box')  # adjustable='box' is important here\n",
    "\n",
    "\n",
    "axres = plt.axes([0.15, 0.1, 0.55, 0.03])\n",
    "sres = Slider(axres, 'Resolution', 0.1, 1.5, valinit=res, valstep=0.1)\n",
    "\n",
    "axfrac = plt.axes([0.15, 0.05, 0.55, 0.03])\n",
    "sfrac = Slider(axfrac, 'Fraction', 0.05, 1, valinit=frac, valstep=0.05)\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    print(\"Hoi\")\n",
    "    res = sres.val\n",
    "    frac = sfrac.val\n",
    "    \n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    \n",
    "    directionalities = calc_all_directionalities(frac, res)\n",
    "    \n",
    "    # redraw axis 1\n",
    "    ax1 = fig.add_subplot(gs[0, 0:3])\n",
    "    ax1.hist(directionalities, bins=50, rwidth=0.85)\n",
    "    \n",
    "    \n",
    "#     ax1.hist(directionalities, bins=50, rwith=0.85)\n",
    "\n",
    "#     scatter2.set_offsets(x, directionalities)   \n",
    "    \n",
    "sfrac.on_changed(update)\n",
    "sres.on_changed(update)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "t = np.arange(0.0, 1.0, 0.001)\n",
    "a0 = 5\n",
    "f0 = 3\n",
    "delta_f = 5.0\n",
    "s = a0 * np.sin(2 * np.pi * f0 * t)\n",
    "\n",
    "l, = plt.plot(t, s, lw=2)\n",
    "\n",
    "ax.margins(x=0)\n",
    "\n",
    "axcolor = 'lightgoldenrodyellow'\n",
    "axfreq = plt.axes([0.25, 0.1, 0.65, 0.03], facecolor=axcolor)\n",
    "axamp = plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n",
    "\n",
    "sfreq = Slider(axfreq, 'Freq', 0.1, 30.0, valinit=f0, valstep=delta_f)\n",
    "samp = Slider(axamp, 'Amp', 0.1, 10.0, valinit=a0)\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    print(\"hoi\", val)\n",
    "    amp = samp.val\n",
    "    freq = sfreq.val\n",
    "    l.set_ydata(amp*np.sin(2*np.pi*freq*t))\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "sfreq.on_changed(update)\n",
    "samp.on_changed(update)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fracs = np.arange(0.05, 1.05, 0.05)\n",
    "res = [0.25, 0.5]\n",
    "\n",
    "for r in res:\n",
    "    for frac in fracs:\n",
    "        directionalities = calc_all_directionalities(frac, r)\n",
    "\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        fig.suptitle(f\"frac {frac}, res{r}\")\n",
    "\n",
    "        gs = fig.add_gridspec(1, 4)\n",
    "        plt.subplots_adjust(left=0.15, bottom=0.2)\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[0, 0:3])\n",
    "        ax1.hist(directionalities, bins=50, rwidth=0.85)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[0, 3])\n",
    "\n",
    "        x = [0] * len(directionalities)\n",
    "\n",
    "        scatter2 = ax2.scatter(x, directionalities)\n",
    "        ax2.set_xlim(-10, 10)\n",
    "        ax2.axes.get_xaxis().set_visible(False)  # remove the x-axis and its ticks\n",
    "        ax2.set_aspect(5, adjustable='box')  # adjustable='box' is important here\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
